{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the following exercieses are based on the tutorial https://medium.com/codebagng/basic-analysis-of-the-iris-data-set-using-python-2995618a6342."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the following data set is already built into Python under the name \"iris\", we will retrieve it here from the internet introducing the command \"read.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `pandas` library as `pd`\n",
    "import pandas as pd\n",
    "names = ['Sepal_length', 'Sepal_width', 'Petal_length', 'Petal_width', 'Species']\n",
    "iris = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header = None, names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the first five rows of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a description of your data (type of variables, numbers, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor variables represent categorical variables. They can thus take on a limited number of different values. Here, \"Species\" can take 3 values.\n",
    "\n",
    "A quick look at the Species attribute through tells you that the number division of the species of flowers is 50-50-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.groupby('Species').size() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can also directly inspect the data set as a whole by simply typing \"iris\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not remain on this high-level overview of the data! Python gives you the opportunity to go more in-depth with the describe() function. This will give you the minimum value, first quantile, median, mean, third quantile and maximum value of the data set Iris for numeric data types. For the class variable, the count of factors will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sepal_length  Sepal_width  Petal_length  Petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also refine your summary overview by adding specific attributes to the command that was presented above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Petal_length  Petal_width\n",
       "count    150.000000   150.000000\n",
       "mean       3.758667     1.198667\n",
       "std        1.764420     0.763161\n",
       "min        1.000000     0.100000\n",
       "25%        1.600000     0.300000\n",
       "50%        4.350000     1.300000\n",
       "75%        5.100000     1.800000\n",
       "max        6.900000     2.500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[['Petal_length','Petal_width']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'matplotlib',https://matplotlib.org, is a powerful visualization tool for python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot iris features 'Sepal_length' (x_axis) and 'Sepal_width' (y_axis) as a scatter plot, use different color to represent different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = set(iris['Species'])\n",
    "\n",
    "x,y = iris['Sepal_length'],  iris['Sepal_width']\n",
    "plt.figure()\n",
    "for name,color in zip(names,('red', 'blue', 'green')):\n",
    "    cond = iris['Species'] == name\n",
    "    plt.scatter(x[cond], y[cond], marker='o', label=name,color =color,alpha=0.5)\n",
    "\n",
    "plt.legend(numpoints=1)\n",
    "plt.xlabel('Sepal_length')\n",
    "plt.ylabel('Sepal_width')\n",
    "plt.legend(loc=9, bbox_to_anchor=(+1.2, 0.6))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can also use Seaborn toolbox, https://seaborn.pydata.org/index.html, to provide a high-level interface for drawing attractive and informative statistical graphics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fc3c327c8b9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use the 'hue' argument to provide a factor variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sepal_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sepal_width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot(x='Sepal_length', y='Sepal_width', data=iris, fit_reg=False, hue='Species', legend=False)\n",
    " \n",
    "# Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You see that there is a high correlation between the sepal length and the sepal width of the Setosa iris flowers, while the correlation is somewhat less high for the Virginica and Versicolor flowers. \n",
    "\n",
    "This holds similarly for the petal length and the sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = iris['Petal_length'],  iris['Petal_width']\n",
    "plt.figure()\n",
    "for name,color in zip(names,('red', 'blue', 'green')):\n",
    "    cond = iris['Species'] == name\n",
    "    plt.scatter(x[cond], y[cond], marker='o', label=name,color=color,alpha=0.5)\n",
    "\n",
    "plt.legend(numpoints=1)\n",
    "plt.xlabel('Petal.Length')\n",
    "plt.ylabel('Petal.Width')\n",
    "plt.legend(loc=9, bbox_to_anchor=(+1.2, 0.6))\n",
    "plt.tight_layout()\n",
    "#plt.axis([x.min()-0.1,x.max()+0.1,y.min()-0.1,y.max()+0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that this graph indicates a positive correlation between the petal length and the petal width for all different species that are included into the Iris data set.\n",
    "\n",
    "we can also use histogram to visualise data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "iris.groupby('Species').Petal_length.hist(alpha=0.4)\n",
    "plt.title('Petal_length')\n",
    "plt.figure()\n",
    "iris.groupby('Species').Petal_width.hist(alpha=0.4)\n",
    "plt.title('Petal_width')\n",
    "plt.figure()\n",
    "iris.groupby('Species').Sepal_length.hist(alpha=0.4)\n",
    "plt.title('Sepal_length')\n",
    "plt.figure()\n",
    "iris.groupby('Species').Sepal_width.hist(alpha=0.4)\n",
    "plt.title('Sepal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have acquired a good understanding of your data, you have to decide on the use cases that would be relevant for your data set. In other words, you think about what your data set might teach you or what you think you can learn from your data. From there on, you can think about what kind of algorithms you would be able to apply to your data set in order to get the results that you think you can obtain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many classifiers require normalization of the data set.\n",
    "\n",
    "When do we need to normalize a dataset? In short: when you suspect that the data is not consistent. You can easily see this when you go through the results of the describe() function. Look at the minimum and maximum values of all the (numerical) attributes. If you see that one attribute has a wide range of values, you will need to normalize your dataset, because this means that the distance will be dominated by this feature. For example, if your dataset has just two attributes, X and Y, and X has values that range from 1 to 1000, while Y has values that only go from 1 to 100, then Y's influence on the distance function will usually be overpowered by X's influence. When you normalize, you actually adjust the range of all features, so that distances between variables with larger ranges will not be over-emphasised.\n",
    "\n",
    "The Iris data set doesn't need to be normalized: the Sepal.Length attribute has values that go from 4.3 to 7.9 and Sepal.Width contains values from 2 to 4.4, while Petal.Length's values range from 1 to 6.9 and Petal.Width goes from 0.1 to 2.5. All values of all attributes are contained within the range of 0.1 and 7.9, which you can consider acceptable. \n",
    "\n",
    "Nevertheless, it's still a good idea to study normalization and its effect, especially if you're new to machine learning. You can perform feature normalization, for example, by first making your own normalize function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x):\n",
    "    num = x - np.min(x)\n",
    "    denom = np.max(x) - np.min(x)\n",
    "    return num/denom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use this argument in another command, where you put the results of the normalization in a data frame through as.data.frame() after the function lapply() returns a list of the same length as the data set that you give in. Each element of that list is the result of the application of the normalize argument to the data set that served as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iris_norm = iris[['Petal_length', 'Petal_width','Sepal_length','Sepal_width']].apply(normalise)\n",
    "iris_norm['Species'] = iris['Species']\n",
    "iris_norm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assess your model's performance later, you will need to divide the data set into two parts: a training set and a test set. The first is used to train the system, while the second is used to evaluate the learned or trained system. In practice, the division of your data set into a test and a training sets is disjoint: the most common splitting choice is to take 2/3 of your original data set as the training set, while the 1/3 that remains will compose the test set.\n",
    "\n",
    "One last look on the data set teaches you that if you performed the division of both sets on the data set as is, you would get a training class with all species of “Setosa” and “Versicolor”, but none of “Virginica”. The model would therefore classify all unknown instances as either “Setosa” or “Versicolor”, as it would not be aware of the presence of a third species of flowers in the data. In short, you would get incorrect predictions for the test set.\n",
    "\n",
    "You thus need to make sure that all three classes of species are present in the training model. What's more, the amount of instances of all three species needs to be present at more or less the same ratio as in your original data set.\n",
    "\n",
    "To make your training and test sets, you first set a seed. This is a number of R's random number generator. The major advantage of setting a seed is that you can get the same sequence of random numbers whenever you supply the same seed in the random number generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you want to make sure that your Iris data set is shuffled and that you have the same ratio between species in your training and test sets. You use the sample() function to take a sample with a size that is set as the number of rows of the Iris data set, or 150. You sample with replacement: you choose from a vector of 2 elements and assign either 0 or 1 to the 150 rows of the Iris data set. The assignment of the elements is subject to probability weights of 0.67 and 0.33.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(2, iris[iris.columns[0]].count(), replace=True,p=[0.67,0.33])\n",
    "print(ind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the replace argument is set to TRUE: this means that you assign a 0 or a 1 to a certain row and then reset the vector of 2 to its original state. This means that, for the next rows in your data set, you can either assign a 0 or a 1, each time again. The probability of choosing a 1 or a 2 should not be proportional to the weights amongst the remaining items, so you specify probability weights.\n",
    "\n",
    "Remember that you want your training set to be 2/3 of your original data set: that is why you assign “0” with a probability of 0.67 and the “1\"s with a probability of 0.33 to the 150 sample rows.\n",
    "\n",
    "You can then use the sample that is stored in the variable ind to define your training and test sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_trainFeatures = iris.loc[ind==0,iris.columns[0:4]]\n",
    "iris_testFeatures = iris.loc[ind==1,iris.columns[0:4]]\n",
    "print(iris_trainFeatures.count())\n",
    "print(iris_testFeatures.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that, in addition to the 2/3 and 1/3 proportions specified above, you don't take into account all attributes to form the training and test sets. Specifically, you only take Sepal.Length, Sepal.Width, Petal.Length and Petal.Width. This is because you actually want to predict the fifth attribute, Species: it is your target variable. However, you do want to include it into the KNN algorithm, otherwise there will never be any prediction for it. You therefore need to store the class labels in factor vectors and divide them over the training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_trainLabels = iris.loc[ind==0,iris.columns[4]]\n",
    "iris_testLabels = iris.loc[ind==1,iris.columns[4]]\n",
    "print(iris_trainLabels.count())\n",
    "print(iris_testLabels.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a powerful machine learning package scikit-learn, including k nearest neighbor classifier (KNN). The theory of KNN will be covered in the lecture. One can also refer to scikit-learn knn documentation for practical guidance: http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all these preparation steps, you have made sure that all your known (training) data is stored. No actual model or learning was performed up until this moment. Now, you want to find the k nearest neighbors of your training set.\n",
    "\n",
    "An easy way to do these two steps is by using the KNeighborsClassifier function, which uses the Euclidian distance measure in order to find the k-nearest neighbours to your new, unknown instance. Here, the k parameter is one that you set yourself. As mentioned before, new instances are classified by looking at the majority vote or weighted vote. In case of classification, the data point with the highest score wins the battle and the unknown instance receives the label of that winning data point. If there is an equal amount of winners, the classification happens randomly.\n",
    "\n",
    "Note the k parameter is often an odd number to avoid ties in the voting scores.\n",
    " \n",
    "To build your classifier, you need to take the KNeighborsClassifier function and simply add some arguments to it, just like in this example:\n",
    "\n",
    "Note KNeighborsClassifier function only takes numpy arrays, so we have to change pandas format into numpy array using .values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_trainFeatures.values;\n",
    "y = iris_trainLabels.values;\n",
    "knnmodel = KNeighborsClassifier(n_neighbors=3)\n",
    "knnmodel.fit(X, y) \n",
    "iris_predLabels = knnmodel.predict(iris_testFeatures.values)\n",
    "print(iris_predLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You store into knnmodel the KNeighborsClassifier function that fits to the training set, and iris_predLabels as the predictions for the test set.\n",
    "\n",
    "Note that you don't want to insert the test labels: these will be used to see if your model is good at predicting the actual classes of your instances!\n",
    "\n",
    "You can retrieve the result of the KNeighborsClassifier function by typing in the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(iris_testLabels,iris_predLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that the model makes reasonably accurate predictions, with the accuracy higher than 0.95.\n",
    "\n",
    "This is already some indication of your model's performance, but you might want to go even deeper into your analysis. For this purpose, you can get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(iris_testLabels,iris_predLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can make a cross tabulation or a contingency table. This type of table is often used to understand the relationship between two variables. In this case, you want to understand how the classes of your test data, stored in iris.testLabels relate to your model that is stored in iris_pred:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance. Again, the theory of Random Forest will be covered in the lecture, but one can refer to https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html for practical guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, normalize feature vectors. In additional to above approach, a more convient way is to use Sklearn build-in normalize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X=iris[['Sepal_length', 'Sepal_width', 'Petal_length', 'Petal_width']]  # Features\n",
    "y=iris['Species']  # Labels\n",
    "\n",
    "# Normalise features\n",
    "X_norm =normalize(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, split training and test data. Again, we can use Sklearn build-in train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting, you will train the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, one can retrieve the result of the RandomForestClassifier function by typing in the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Important Features in Scikit-learn##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important advantages of random forest is that it is able to find the feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization, you can use a combination of matplotlib and seaborn. Because seaborn is built on top of matplotlib, it offers a number of customized themes and provides additional plot types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "feature_names = ['Sepal_length', 'Sepal_width', 'Petal_length', 'Petal_width'] # This should be consistent with X=iris[['Sepal_length', 'Sepal_width', 'Petal_length', 'Petal_width']] \n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
